{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d2c241-d313-426f-85d0-7eaaeebb8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42839cc1-222a-48c5-b3d7-4cec2a84c559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf66516-a63b-4bde-ac2f-93fbc22dc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/06 22:05:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#object that we use to interact with spark, our main entry point to spark\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784d33b4-7a4e-49e4-aece-500856fdfa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 22:05:08--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.160.226.85, 3.160.226.111, 3.160.226.161, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.160.226.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64346071 (61M) [binary/octet-stream]\n",
      "Saving to: ‘yellow_tripdata_2024-10.parquet.5’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  61.36M   107MB/s    in 0.6s    \n",
      "\n",
      "2025-03-06 22:05:08 (107 MB/s) - ‘yellow_tripdata_2024-10.parquet.5’ saved [64346071/64346071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1a80d3-0e2b-4cfa-8155-5bdf4861e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254534 yellow_tripdata_2024-10.parquet\n"
     ]
    }
   ],
   "source": [
    "!wc -l yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3185228-0c68-4655-afb9-71fee1419279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa32f321-a4b6-4cb2-a473-a090594d98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c79e18-9e02-4f4c-87e1-d75e05f841e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('yellow_tripdata_2024-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559b3f90-9c5d-42fe-a0cd-750ea56b1c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2024-10-01 00:30:44|  2024-10-01 00:48:26|              1|          3.0|         1|                 N|         162|         246|           1|       18.4|  1.0|    0.5|       1.5|         0.0|                  1.0|        24.9|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:12:20|  2024-10-01 00:25:25|              1|          2.2|         1|                 N|          48|         236|           1|       14.2|  3.5|    0.5|       3.8|         0.0|                  1.0|        23.0|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:04:46|  2024-10-01 00:13:52|              1|          2.7|         1|                 N|         142|          24|           1|       13.5|  3.5|    0.5|       3.7|         0.0|                  1.0|        22.2|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:12:10|  2024-10-01 00:23:01|              1|          3.1|         1|                 N|         233|          75|           1|       14.2|  3.5|    0.5|       2.0|         0.0|                  1.0|        21.2|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:30:22|  2024-10-01 00:30:39|              1|          0.0|         1|                 N|         262|         262|           3|        3.0|  3.5|    0.5|       0.0|         0.0|                  1.0|         8.0|                 2.5|        0.0|\n",
      "|       2| 2024-10-01 00:31:20|  2024-10-01 00:36:00|              2|         0.97|         1|                 N|         137|         137|           1|        7.2|  1.0|    0.5|      2.44|         0.0|                  1.0|       14.64|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:42:57|  2024-10-01 00:49:01|              1|          1.3|         1|                 N|         142|          48|           1|        7.9|  3.5|    0.5|      2.55|         0.0|                  1.0|       15.45|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:59:55|  2024-10-01 01:02:24|              1|          0.5|         1|                 N|         230|         161|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:00:47|  2024-10-01 00:04:22|              0|          1.1|         1|                 N|         142|         237|           1|        7.2|  3.5|    0.5|       3.0|         0.0|                  1.0|        15.2|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:17:36|  2024-10-01 00:26:22|              1|          2.2|         1|                 N|         162|         145|           1|       11.4|  3.5|    0.5|       3.3|         0.0|                  1.0|        19.7|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:49:00|  2024-10-01 00:52:20|              1|          0.6|         1|                 N|         229|         162|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|\n",
      "|       2| 2024-10-01 00:07:26|  2024-10-01 00:13:20|              1|          0.9|         1|                 N|         162|         162|           1|        7.9|  1.0|    0.5|      3.87|         0.0|                  1.0|       16.77|                 2.5|        0.0|\n",
      "|       2| 2024-10-01 00:17:11|  2024-10-01 00:25:00|              1|         1.33|         1|                 N|         162|         230|           1|        9.3|  1.0|    0.5|       2.0|         0.0|                  1.0|        16.3|                 2.5|        0.0|\n",
      "|       2| 2024-10-01 00:00:34|  2024-10-01 00:05:13|              1|         1.79|         1|                 N|         211|         234|           1|        9.3|  1.0|    0.5|      2.86|         0.0|                  1.0|       17.16|                 2.5|        0.0|\n",
      "|       2| 2024-09-30 23:58:40|  2024-10-01 00:20:26|              1|         5.16|         1|                 N|         142|           7|           1|       24.7|  1.0|    0.5|       0.0|         0.0|                  1.0|        29.7|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:55:29|  2024-10-01 01:42:35|              1|         11.3|        99|                 N|         161|         197|           1|       39.5|  0.0|    0.5|       0.0|        6.94|                  1.0|       47.94|                 0.0|        0.0|\n",
      "|       1| 2024-10-01 00:08:59|  2024-10-01 00:40:58|              1|         20.6|         1|                 N|         132|         243|           2|       76.5| 2.75|    0.5|       0.0|        6.94|                  1.0|       87.69|                 0.0|       1.75|\n",
      "|       2| 2024-10-01 00:18:38|  2024-10-01 00:36:47|              2|         7.42|         1|                 N|         239|         247|           4|      -33.1| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -38.1|                -2.5|        0.0|\n",
      "|       2| 2024-10-01 00:18:38|  2024-10-01 00:36:47|              2|         7.42|         1|                 N|         239|         247|           4|       33.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        38.1|                 2.5|        0.0|\n",
      "|       2| 2024-10-01 00:39:33|  2024-10-01 00:53:59|              1|         4.49|         1|                 N|         247|          60|           2|       21.9|  1.0|    0.5|       0.0|         0.0|                  1.0|        24.4|                 0.0|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20608b54-9f41-4808-b803-c0f64087076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3833771\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b1992e-c723-4a27-a30e-dc95b33683db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd9bc2b-a61e-4d47-96ac-7b16f299db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 101 yellow_tripdata_2024-10.parquet > head.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b36f464c-36ce-4a9c-a9c2-e61117e3e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAR1\u0015\u0004\u0015\u0010\u0015\"L\u0015\u0004\u0015\u0000\u0012\u0000\u0000(�/�A\u0000\u0000\u0002\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0015\u0000\u0015��\u0013\u0015��\u000e,\u0015���\u0001\u0015\u0010\u0015\u0006\u0015\u0006\u001c",
      "\u0018\u0004\u0002\u0000\u0000\u0000\u0018\u0004\u0001\u0000\u0000\u0000\u0016\u0000(\u0004\u0002\u0000\u0000\u0000\u0018\u0004\u0001\u0000\u0000\u0000\u0000\u0000\u0000(�/���h\u0002\u0000�H\f",
      "\u000e\u0000`EbS\u0010hf���F�\u0017Yi��a�\u0005��\u001c",
      "s��1w'�\n",
      "3�>\u0010�9L�Z�\t\u0001��&�e\u0006�^#\u0002'L���H�\u0015����y��\u0010�����_�q�]T��\u0003\u000f�\u0002�.r1���ԟAC��gdL���`\u000b",
      "�Ճ=�(��a�2h�]o�o5&gs_�J\u001f��\u000fr_��\u0014��\u0013�_.���f�>5�\u0003z��c��\u0004���.�oC\u001a�\"{�\u000e��1�\u0011{�t��v\u0011 ��4M�v���u=y3ƁP��v\u0010�\t�m�K_���J\u001c",
      "n����q�f����튘;ij����\t�c\u000f\n",
      "��\u0018��\u001fw�1��\u0012ͤ�T(=�r� ��E�\u0004�-�P��A��\u0017O}\u001bX?$��S��JI�\u0014��L�z\u001bQ�7��\u0013�&\u001e",
      "��\u0004���ЧL\u001c",
      "��z;��\u001e",
      "\u001c",
      "9���\u001d",
      "�\u0005����M���\u001c",
      "����/�k`��W�f����Om=����>5d�{�H>X���p�\tv����iq���=գ�~ܱ�_��jH�\u0005����Ճ�C\u001f�D�\u000fs�\u001fٯ�ol��6�[*f����(���4L�m\u0016�}r�޿{D\u0000 ߒw�� ���\u001f+U��W[��J��P:�LjD.����\u0003.\u001f��\\\u0018wk���r��\u0010\u0016���e��!\"�ߵ\u0000=���e�Ǔ�A~�\u0017����:��ow�ݯ�U�U�[q�z\u0007t��~�Uz\u0016ɇ>��\u0013�_�1�A�8F{p��\u001d",
      "-Z̗�N�@\u0011Ӈݷ=��믪�G K��p�\u0012�>uZ{\u0001ۥO���l����I2�\u001b��h����)R�*ۋ��I�|\"�}�)�+�SCQ�w�5wС{I��}�L\u001f�~���\u0017\u001aׇLr=��\u001e",
      ",!1}�����z��8ID��n=5Q�ܦ��o�n���L\u001f�2�����m�F�ӏ\u0018�`�у[��>�^=���]��\f",
      "�H�/hѧB��m\u0015\f",
      "�\u001fk�v?,����b�r��S�I��P�S�\u0010������Q��\u0001�oC��Ō�Q h�\u001a�ۖG�y���( �\u001d",
      "RGׯ����U�qߖ���l\u0007q\u000f�z��P�\u0012�c�(F�\u000e�\u001aO�mHfb��Wz�}��R�����Řѫ>\u0004r[���n\u00133W?�mB���t��p\u0007�>\u0010\u001e",
      "�\u0003[���y-q�;j\ts\u0004��Σ\f",
      "��^��\u0001��|.�FC���S{�^��Y��\u0015G_v������e��7\u001b�����\u001f��I(�t��5\u001d",
      "�^\u0006�\u0012T��G\u0016cW*)}�L1��\u0001X1f�\n",
      "��\\.#&#���}�/���wz��U���\u001a���2O��\u0016m���6!�\u001flK\u000f\u0015� ��\\�~�.�\u0005/\u001fe.��y\u0007{�Ve��\u0015�rR\u0000�H=X�9t\u001f���YK����V,ԯ�\u0012��}\u001b!/z\u0016�G��h\t�︘>�>��w�\u000f�����SR�~�~�o��\u001f�-�Q1N>{tױ������b՞��t{7����e�w��\n",
      "��ܗQ$D?rC@�?�#\u001bF\u0013��h����G�L_#����Ͷ��xy\u0018�ǩ�\u0019�D���}���}�'i���ǫG��k�Tc١\u001c",
      "�,�V����r��1�\u001f�LC�������ճj߆o.s�)�C�E_°��\u001b\u0016�\u0005�>���S'�|{��\u0014_�\u0010����ANWe{0H��q�'�\u0007�l�q\u001f=\"z��$�舠�ά_���\"�N�\u000b",
      "��%Ѫ/\u001fK��\u001b]J���?�(\f",
      "�$0��u1/G�8J=X6}X�)��T�<���X���\u0017�܆JO�x�2Z�Zσ\u0017D��L?C<˫å]�E\"1\u001b\u0013��y�Ջe���<��/zҪ�G���6�,��k4�>�z��zS�����``��\u0018�A��,�\u001e",
      "�b\u0014��qG�g�,�l\tq1r�Sgۗ'�tp�M2\u001c",
      "�Ao'\t�\u000e��=�Y�ԣʦO��#Dܿ���6���7^�'\u0017���C�α\u00075p�Ȗ��O�x\u001f�`z\u0010����h�\u0012\u0004�N\u0016�\u0015\u0003�q�\n",
      "�\f",
      "�[9�g���K\u0014%�\u001aU��\u0013\t���\u0001\u0001�p��u\u0003�H�BOn��r\u001fu�p=��/��'ɬ�V����@����H\u001c",
      ">�!>{�\u0012���X3\u0004B\u001c",
      "��4}�Y�\u0000�݊1�hm{\u0017I��Q}�=��r��``�[R\u000b",
      "H�H�G�\u000e�\f",
      "ѣ���ڷ��\u0017E0��<\u0000��C�\u000e)i`d\u001e",
      "�0z�\u00163�����;�:`+w��ޫ���nIL�����7\u001a��8O�7-N�\u001c",
      "���j0�`\n",
      "�t�\\��#�\u0007�2F��.�6�W�T���7g\u0013$��(�>8\u0001�\u000fg���P�G,�ES�!`��F3�a��#�F��.nX�\n",
      "�6�,�5DK_��d\u0003�諲��$֧Jw1\tW���v�;�\u0007�\"4�S��S\u001f~��������P�\u000b",
      "Iw\u0007��Bc\u0004��?x��=\u0007S�\u0007\"������x�d�^�\u0014z��tb�zq5r=\u000f&J�'a.׏�\u0007mӧ\u0016�\u001fO������ ����T?��\u0017w\u0000�0�7b\n",
      "���\\�t�߬,ף�Eo��GY\u0019\u001c",
      "�G  !S�W\u0017��A��>$`��#0^-Y�-5�.>qN`���\n",
      "Lߪ��\u001a���s3��}�%G�=eM�[ �6��\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 head.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70aab8ca-971e-45f9-b038-808f206cb89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/nico/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: pyarrow in /home/nico/anaconda3/lib/python3.12/site-packages (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/nico/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nico/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nico/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nico/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/nico/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aabfcb6-d527-4ddc-8091-c63eb845d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e810c61-f60e-451c-9b31-ed982b560d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec4fae4-5a13-4373-9d0c-2e3bd037316a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/home/nico/notebooks/2024/10 already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mparquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024/10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/readwriter.py:1140\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39mparquet(path)\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/home/nico/notebooks/2024/10 already exists."
     ]
    }
   ],
   "source": [
    "df.write.parquet('2024/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04385c1e-40c5-4270-a06e-20acd08b57b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du: cannot access 'sh': No such file or directory\n",
      "102780\t2024/10\n"
     ]
    }
   ],
   "source": [
    "!du sh 2024/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5930a844-91c8-453b-be16-f710028d1db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 nico nico 25M Mar  6 21:02 2024/10/part-00000-b2341259-f07b-49ac-8e23-7e4bf7f6aaeb-c000.snappy.parquet\n",
      "-rw-r--r-- 1 nico nico 25M Mar  6 21:02 2024/10/part-00001-b2341259-f07b-49ac-8e23-7e4bf7f6aaeb-c000.snappy.parquet\n",
      "-rw-r--r-- 1 nico nico 25M Mar  6 21:02 2024/10/part-00002-b2341259-f07b-49ac-8e23-7e4bf7f6aaeb-c000.snappy.parquet\n",
      "-rw-r--r-- 1 nico nico 25M Mar  6 21:02 2024/10/part-00003-b2341259-f07b-49ac-8e23-7e4bf7f6aaeb-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh 2024/10/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e064e09-6dc8-4ddc-848f-06cab617f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df_filtered = df.filter(to_date(df[\"tpep_pickup_datetime\"]) == \"2024-10-15\")\n",
    "trip_count = df_filtered.count()\n",
    "print(trip_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348db208-c3dc-4c59-8612-5a85e9af1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"tpep_pickup_datetime\").summary().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a199c0e-5b65-4fe7-8bc1-a2f41a100cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"tpep_pickup_datetime\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b250a75-e68d-426f-822f-082f5f8846be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "df_filtered = df.filter(to_date(col(\"tpep_pickup_datetime\")) == \"2024-10-15\")\n",
    "print(df_filtered.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2245d07c-70fd-4aaa-a573-26c9edc36303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|max(trip_duration_hours)|\n",
      "+------------------------+\n",
      "|      162.61777777777777|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, max\n",
    "\n",
    "df.withColumn(\"trip_duration_hours\", \n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 3600\n",
    ").agg(max(\"trip_duration_hours\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d86b0101-3196-4241-9ed9-dadaad2f8ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 22:08:42--  https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.160.226.111, 3.160.226.228, 3.160.226.161, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.160.226.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12331 (12K) [text/csv]\n",
      "Saving to: ‘taxi_zone_lookup.csv.1’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-06 22:08:42 (201 MB/s) - ‘taxi_zone_lookup.csv.1’ saved [12331/12331]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "261961e0-363e-4ae4-82b5-f7067f530b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.csv(\"taxi_zone_lookup.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3825d1ed-bb3a-4df8-b3b6-6fe66f8421fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView(\"taxi_zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20eef9f4-07fb-4226-a616-4b2ac48d6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"yellow_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de41eb40-649a-45c8-adf0-819eb4eb3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                Zone|pickup_count|\n",
      "+--------------------+------------+\n",
      "|Governor's Island...|           1|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT z.Zone, COUNT(*) AS pickup_count\n",
    "    FROM yellow_trips yt\n",
    "    JOIN taxi_zones z\n",
    "    ON yt.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY pickup_count ASC\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691298f2-881e-4ce4-b2f0-0b1725581b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
